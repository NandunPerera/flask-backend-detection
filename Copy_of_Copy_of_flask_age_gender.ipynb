{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NandunPerera/flask-backend-detection/blob/main/Copy_of_Copy_of_flask_age_gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYBJga0Y4j8N"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tmgvUcW6CEm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MevKe1KFWgvi"
      },
      "source": [
        "# Data Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BjFATpbWg9Y"
      },
      "outputs": [],
      "source": [
        "# dir_ = '/content/drive/MyDrive/flask/models/'\n",
        "# gender = dir_ +  'model_gender.h5'\n",
        "# age_v2 = dir_ +  'model_age_v2.h5'\n",
        "# age_v1 = dir_ +  'age_mode_vN.h5'\n",
        "\n",
        "YOUR_APP_NAME = \"g10-age-gender\"\n",
        "url_gen = f'https://{YOUR_APP_NAME}.herokuapp.com/v1/models/gender:predict'\n",
        "url_age = f'https://{YOUR_APP_NAME}.herokuapp.com/v1/models/age:predict'\n",
        "\n",
        "# INDEX_PATH = '/content/drive/MyDrive/flask/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TS7oByaWgl9"
      },
      "source": [
        "# App Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egrmcxBSjUEL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSXI4C8LjX8i"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, redirect, url_for, request, render_template\n",
        "from flask_ngrok import run_with_ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGmZFMOPX8Y7"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import dlib\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foCncsntYcTR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwBKUZvqYF83"
      },
      "outputs": [],
      "source": [
        "def detect_faces(image):\n",
        "    # Create a face detector\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    # Run detector and get bounding boxes of the faces on image.\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    face_frames = [(x.left(), x.top(), x.right(), x.bottom()) for x in\n",
        "                   detected_faces]\n",
        "\n",
        "    return face_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stZbnid_xlvH"
      },
      "outputs": [],
      "source": [
        "def make_prediction(instances, many=False,isAge = False):\n",
        "    if not many:\n",
        "        data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [instances.tolist()]})\n",
        "    else:\n",
        "        data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": instances.tolist()})\n",
        "    headers = {\"content-type\": \"application/json\"}\n",
        "    if(not isAge):\n",
        "      json_response = requests.post(url_gen, data=data, headers=headers)\n",
        "    else:\n",
        "      json_response = requests.post(url_age, data=data, headers=headers)\n",
        "    jj = json.loads(json_response.text)\n",
        "    return jj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3OrCPbQ6-J_"
      },
      "source": [
        "# External Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgJ-T5cwxe0b"
      },
      "outputs": [],
      "source": [
        "# def model_predict_serving(img_path):\n",
        "#     test_image = io.imread(img_path)\n",
        "#     detected_faces = detect_faces(test_image)\n",
        "\n",
        "#     classes = [ 'Male' , 'Female' ]\n",
        "\n",
        "#     for n, face_rect in enumerate(detected_faces):\n",
        "#         face = Image.fromarray(test_image).crop(face_rect)\n",
        "#         face_array = tf.keras.preprocessing.image.img_to_array(face)\n",
        "#         face_img = tf.keras.preprocessing.image.array_to_img(face_array)\n",
        "\n",
        "#         dim_age = (200, 200)\n",
        "#         dim_gender = (128, 128)\n",
        "#         resized_age_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_age) / 255\n",
        "#         resized_gender_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_gender) / 255\n",
        "\n",
        "#         p_gender =  make_prediction(np.expand_dims( resized_gender_arr , 0 ),many = True)\n",
        "#         p_age = make_prediction(np.expand_dims( resized_age_arr , 0 ),many = True, isAge= True)\n",
        "\n",
        "#         gender = classes[np.argmax(p_gender['predictions'][0])]\n",
        "#         age = round((p_age['predictions'][0])[0] * 116)\n",
        "#         print(age,gender)\n",
        "        \n",
        "#         face_img = tf.keras.preprocessing.image.array_to_img(resized_age_arr)\n",
        "\n",
        "#         return f'Gender: {gender} | Age: {age}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P6PaPvL7HYp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image preprocessing nandun"
      ],
      "metadata": {
        "id": "Igu3tKFAHaoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def loadImage(filepath):\n",
        "#   test_img = image.load_img(filepath, target_size=(200, 200))\n",
        "#   test_img = image.img_to_array(test_img)\n",
        "#   test_img = np.expand_dims(test_img, axis = 0)\n",
        "#   test_img /= 255\n",
        "#   return test_img"
      ],
      "metadata": {
        "id": "M51PihwbHf2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC9UZMVr68C-"
      },
      "source": [
        "# Local Predict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOHEVNoYVD8T",
        "outputId": "434063f5-dafe-459a-b8e9-85d504c53c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fer\n",
            "  Downloading fer-22.4.0-py3-none-any.whl (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fer) (2.23.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fer) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n",
            "Collecting mtcnn>=0.1.1\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn>=0.1.1->fer) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->fer) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fer) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (3.0.4)\n",
            "Installing collected packages: mtcnn, fer\n",
            "Successfully installed fer-22.4.0 mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER"
      ],
      "metadata": {
        "id": "d0Sf8cZ2VHiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_detector = FER(mtcnn=True)"
      ],
      "metadata": {
        "id": "vCzONwsVVOAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XLlANRp6VWJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install deepface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY6CAuhonJeS",
        "outputId": "5c1d1af4-0023-496a-d501-da187e1d286b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.75-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.8.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.3.5)\n",
            "Collecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.12-py3-none-any.whl (15 kB)\n",
            "Collecting fire>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting opencv-python>=4.5.5.64\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 1.2 MB/s eta 0:00:01\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from deepface import DeepFace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "NwX4JsSknKah",
        "outputId": "51efa17f-76bb-4572-8d06-e7d07f991abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9992a767273a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepface'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(img_path):\n",
        "    # face_analysis = DeepFace.analyze(img_path)\n",
        "\n",
        "    test_img = io.imread(img_path)\n",
        "\n",
        "    dominant_emotion, emotion_score = emotion_detector.top_emotion(test_img)\n",
        "    \n",
        "    return dominant_emotion\n",
        "\n",
        "\n",
        "    # return f'emotion{face_analysis[\"dominant_emotion\"]}| age:{face_analysis[\"age\"]}'"
      ],
      "metadata": {
        "id": "tPOLLcvSlor8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQAglKrBaY3M"
      },
      "outputs": [],
      "source": [
        "# def model_predict(img_path):\n",
        "#     test_image = io.imread(img_path)\n",
        "#     detected_faces = detect_faces(test_image)\n",
        "\n",
        "#     classes = [ 'Male' , 'Female' ]\n",
        "\n",
        "#     for n, face_rect in enumerate(detected_faces):\n",
        "#         face = Image.fromarray(test_image).crop(face_rect)\n",
        "#         face_array = tf.keras.preprocessing.image.img_to_array(face)\n",
        "#         face_img = tf.keras.preprocessing.image.array_to_img(face_array)\n",
        "\n",
        "#         dim_age = (200, 200)\n",
        "#         dim_gender = (128, 128)\n",
        "#         resized_age_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_age) / 255\n",
        "#         resized_gender_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_gender) / 255\n",
        "\n",
        "#         pred_gen = model_gender.predict( np.expand_dims( resized_gender_arr , 0 ) )[0]\n",
        "#         pred_age_v1 = int(model_age_v1.predict(loadImage(img_path) )*116)\n",
        "#         pred_age_v2 = model_age_v2.predict( np.expand_dims( resized_age_arr , 0 ) )\n",
        "\n",
        "#         print(pred_age_v2[0] * 116 , pred_age_v2[1] * 116)\n",
        "        \n",
        "#         label_g = classes[ np.argmax( pred_gen ) ]\n",
        "#        # label_a_v1 = round(pred_age_v1[0].tolist()[0] * 116)\n",
        "#         label_a_v1 = pred_age_v1\n",
        "#         label_a_v2 = round((((pred_age_v2[0] * 116 + pred_age_v2[1] * 116)/2)[0]).tolist()[0])\n",
        "#         face_img = tf.keras.preprocessing.image.array_to_img(resized_age_arr)\n",
        "#         label_emotion = predict_emotion(img_path)\n",
        "\n",
        "\n",
        "\n",
        "#         return f'Gender: {label_g} | Age(V1): {label_a_v1} | Age(V2): {label_a_v2} | emotion: {label_emotion}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk5Oz-LN7EhQ"
      },
      "source": [
        "# External with Alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIylGPzN7L1s"
      },
      "outputs": [],
      "source": [
        "# predictor_path = '/content/drive/MyDrive/flask/shape_predictor_68_face_landmarks.dat'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtbBCOvy7CUm"
      },
      "outputs": [],
      "source": [
        "def model_predict_serving_align(img_path):\n",
        "    classes = [ 'Male' , 'Female' ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    sp = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "    test_img = io.imread(img_path)\n",
        "    dets = detector(test_img, 1)\n",
        "\n",
        "    num_faces = len(dets)\n",
        "    if num_faces == 0:\n",
        "      return \"Sorry, there were no faces found\"\n",
        "      \n",
        "    \n",
        "    #detected_faces = detect_faces(test_image)\n",
        "\n",
        "    faces = dlib.full_object_detections()\n",
        "    for detection in dets:\n",
        "        faces.append(sp(test_img, detection))\n",
        "    \n",
        "\n",
        "    images = dlib.get_face_chips(test_img, faces,size = 200,padding = 0.25 )\n",
        "\n",
        "    for face in images:\n",
        "        plt.subplot(1, len(images), n+1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(face)\n",
        "\n",
        "        face_array = tf.keras.preprocessing.image.img_to_array(face)\n",
        "        face_img = tf.keras.preprocessing.image.array_to_img(face_array)\n",
        "\n",
        "        dim_age = (200, 200)\n",
        "        dim_gender = (128, 128)\n",
        "        resized_age_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_age) / 255\n",
        "        resized_gender_arr = tf.keras.preprocessing.image.smart_resize(face_array,size=dim_gender) / 255\n",
        "\n",
        "        p_gender =  make_prediction(np.expand_dims( resized_gender_arr , 0 ),many = True)\n",
        "        p_age = make_prediction(np.expand_dims( resized_age_arr , 0 ),many = True, isAge= True)\n",
        "\n",
        "        gender = classes[np.argmax(p_gender['predictions'][0])]\n",
        "        age = round((p_age['predictions'][0])[0] * 116)\n",
        "        label_emotion = predict_emotion(img_path)\n",
        "        print(age,gender)\n",
        "        \n",
        "        face_img = tf.keras.preprocessing.image.array_to_img(resized_age_arr)\n",
        "\n",
        "        return f'Gender: {gender}|Age: {age}|emotion:{label_emotion}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tm-rUxq7A8v"
      },
      "source": [
        "# Flask Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOt9BfDNabCJ"
      },
      "outputs": [],
      "source": [
        "# Load your trained model\n",
        "model_gender = keras.models.load_model(gender)\n",
        "model_age_v1 = keras.models.load_model(age_v1)\n",
        "model_age_v2 = keras.models.load_model(age_v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5zwTW0sa6W5"
      },
      "outputs": [],
      "source": [
        "#Template Folder Path\n",
        "TEMPLATE_PATH = '/template'\n",
        "STATIC_PATH = '/static'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riarg_A0a4b7"
      },
      "outputs": [],
      "source": [
        "# Define a flask app\n",
        "app = Flask(__name__,template_folder=TEMPLATE_PATH,static_folder=STATIC_PATH)\n",
        "# run_with_ngrok(app)  # Start ngrok when app is run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEamwghV74Ba"
      },
      "outputs": [],
      "source": [
        "# !pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aMctWz_8ouc"
      },
      "outputs": [],
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL_VBu4T81Kg"
      },
      "outputs": [],
      "source": [
        "# !tar -xvf /content/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpijkmvS86GB",
        "outputId": "1b30e5ba-15ed-4731-d3ea-7d4018ca89fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# !./ngrok authtoken 28mYPYUE6RZ4JilKi7A0wUqIlHU_7B3KXBbRG5xBBCGq8zdnj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cg6dQoo48od"
      },
      "outputs": [],
      "source": [
        "# @app.route('/', methods=['GET'])\n",
        "# def index():\n",
        "#     # Main page\n",
        "#     return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def upload():\n",
        "    if request.method == 'POST':\n",
        "        # Get the file from post request\n",
        "        f = request.files['file']\n",
        "        print(f.filename)\n",
        "        # Save the file to ./uploads\n",
        "        basepath = '/content'\n",
        "        file_path = os.path.join(\n",
        "            basepath, 'sample_data', f.filename)\n",
        "        f.save(file_path)\n",
        "        print(file_path)\n",
        "        # Make prediction | Involves Model\n",
        "        # predictions = model_predict(file_path) #Predict Locally\n",
        "       predictions = model_predict_serving_align(file_path) #Predict with TFServing\n",
        "        print(predictions)\n",
        "\n",
        "        return predictions \n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_RYBH5Ppgyy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Copy of flask-age-gender",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}